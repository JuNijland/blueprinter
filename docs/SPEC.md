# Blueprinter — Product Specification

## Overview

Blueprinter is an event-driven data broker that monitors web pages for changes to structured entities and emits events when they occur. It targets use cases where businesses need real-time awareness of changes on the web: price monitoring, listing position tracking, job vacancy intelligence, and more.

## Use Cases

### Price Monitoring in E-commerce

A retailer has agreements with resellers about minimum pricing for their products. A reseller may quietly drop below the agreed price — whether on a marketplace like Amazon or Bol.com, or on their own store. Blueprinter detects these price changes and alerts the retailer in real time.

### Listing Position Tracking

A retailer wants to know when their product moves up or down in search results for a given query on a marketplace. Blueprinter tracks listing positions over time and emits events when rankings shift.

### Recruitment Intelligence

When a company posts a new job vacancy, recruiters can be notified immediately. If a listing remains open after 90 days, that may signal the company is struggling to fill the role — and could be more receptive to external recruitment efforts. Blueprinter can emit events for both scenarios.

---

## Domain Model

### Sources

A Source represents an external website or platform that we extract data from (e.g., Bol.com, Amazon.nl, Indeed.nl).

Sources are org-scoped. Each source has a `base_url` and a `name`. A source can have multiple Blueprints associated with it (one per page type — search results, product detail, category listing, etc.).

### Entity Schemas

Entity Schemas define the shape of structured data we extract. They are **system-wide and static** — not user-defined. Examples:

- **E-commerce Product**: name, price, currency, seller, image_url, rating, review_count, availability
- **Job Vacancy**: title, company, location, salary_min, salary_max, employment_type, posted_date, description_snippet

For MVP, we ship with 2 schemas: `ecommerce_product` and `job_vacancy`. Schemas are defined in code (both in Go for extraction and in TypeScript for display), not in the database.

### Blueprints

A Blueprint is a JSON definition that describes how to extract entities from a specific page type on a source using XPaths.

Key properties:
- Tied to one Source and one Entity Schema
- Describes extraction rules for either a **single item** or a **list of items**
- Generated by feeding cleaned HTML + entity schema to an LLM (OpenAI)
- Has a `status`: `draft`, `active`, `failed`, `archived`
- Includes `test_url` — the URL used to generate/test the blueprint
- Stores the XPath mappings as JSONB (`extraction_rules`)

Blueprint generation happens exclusively in the Go worker. The web app calls the worker via gRPC to:
1. Fetch and clean HTML from a URL (via Firecrawl)
2. Generate a blueprint from the HTML + schema
3. Test a blueprint against a URL to verify extraction works

### Entities

Entities are the structured records we track. Rather than storing full snapshots on every check, entities store their **current state** and we reconstruct history from events.

Key properties:
- Tied to one Source and one Entity Schema
- `external_id`: identifier derived from the source (e.g., product SKU, listing URL slug)
- `content`: JSONB blob matching the entity schema
- `first_seen_at`, `last_seen_at`: lifecycle tracking
- `status`: `active`, `stale` (not seen in recent checks), `removed`

Entity identity is determined by `org_id` + `source_id` + `schema_type` + `external_id`. The external_id extraction strategy is defined in the blueprint.

### Watches

A Watch is a scheduled job tied to a specific URL on a source. It runs periodically, extracts entities using the associated Blueprint, and diffs the results against stored entities.

Key properties:
- Tied to one Source and one Blueprint
- `url`: the specific URL to monitor (e.g., a search query URL, a category page)
- `schedule`: cron expression (e.g., `*/30 * * * *` for every 30 minutes)
- `status`: `active`, `paused`, `error`
- `last_run_at`, `next_run_at`: scheduling metadata
- `last_error`: text, nullable — stores the most recent error message
- `consecutive_failures`: integer — for circuit-breaking logic

When a watch runs:
1. Fetch HTML from the URL via Firecrawl
2. Extract entities using the associated Blueprint
3. Diff extracted entities against stored entities
4. Emit events based on detected changes
5. Update entity states

### Diff Engine

The diff engine compares newly extracted entities against stored state and produces change events. Matching is done by `external_id`.

Change types detected:
- **entity_appeared**: New entity found that wasn't previously tracked
- **entity_disappeared**: Previously tracked entity no longer found
- **entity_changed**: One or more fields differ from stored state

For `entity_changed`, the diff is **field-level**: we compare each field in the entity schema and record which fields changed, with old and new values. Diffing rules:
- Strings: trimmed, case-sensitive comparison
- Numbers: exact comparison (prices stored as integers in cents to avoid float issues)
- Null handling: null → value = appeared, value → null = disappeared, null → null = no change

### Events

Events are the core output of Blueprinter. Each event records a specific change detected by a watch run.

Key properties:
- `event_type`: one of `entity_appeared`, `entity_disappeared`, `entity_changed`, `watch_error`
- `watch_id`, `entity_id`: foreign keys to the triggering watch and affected entity
- `payload`: JSONB containing event-specific data
- `occurred_at`: when the change was detected

Payload examples:
```json
// entity_changed
{
  "changes": [
    { "field": "price", "old": 2999, "new": 2499 },
    { "field": "availability", "old": "in_stock", "new": "out_of_stock" }
  ]
}

// entity_appeared
{
  "entity": { "name": "Product X", "price": 1999, ... }
}
```

### Subscriptions

A Subscription lets users subscribe to specific event types, apply optional filters, and route events to channels.

Key properties:
- `event_types`: array of event types to subscribe to (e.g., `["entity_changed", "entity_disappeared"]`)
- `filters`: JSONB — optional conditions (e.g., `{"field": "price", "direction": "decreased"}`)
- `channel_type`: `webhook`, `email`, `slack`
- `channel_config`: JSONB — channel-specific settings (URL, email address, Slack webhook URL)
- `status`: `active`, `paused`

Optional scoping:
- `source_id`: limit to events from a specific source (nullable)
- `watch_id`: limit to events from a specific watch (nullable)
- If both are null, the subscription matches all events in the org.

Post-MVP: batching support (digest mode — aggregate events and deliver on a schedule instead of immediately).

### Deliveries

Deliveries implement the **transactional outbox pattern** to guarantee reliable event delivery.

When an event is created:
1. Find all matching subscriptions (by event type, filters, scope)
2. Create one delivery row per matching subscription in the **same transaction** as the event

Delivery lifecycle:
- `status`: `pending` → `delivered` or `failed`
- Retry with exponential backoff: 1min, 5min, 30min, 2h (max 5 attempts)
- Tracks: `attempts`, `last_error`, `next_retry_at`, `delivered_at`

After max retries, status becomes `failed` and stays there. The subscription is **not** automatically paused — but consecutive failures across deliveries for the same subscription could trigger a warning (post-MVP).

---

## Authentication & Multitenancy

### WorkOS Integration

- Use WorkOS AuthKit for authentication (sign-up, sign-in, SSO, org management)
- The web app redirects to WorkOS for auth flows — no custom login pages
- Session management via WorkOS middleware in Next.js

### Multitenancy Model

- Every data table includes `org_id text not null` referencing the WorkOS organization ID
- All queries in both web (Drizzle) and worker (sqlc) must filter by `org_id`
- No row-level security in Postgres (application-level filtering is sufficient for now)
- We do **not** sync users or organizations into our own database — we query WorkOS at runtime when we need user/org info

### User Roles (MVP)

- All organization members have full access (no role differentiation for MVP)
- WorkOS handles org membership and invitations

---

## Communication: Web ↔ Worker

### ConnectRPC

The web app communicates with the worker via ConnectRPC (HTTP-based gRPC).

Service definition (`BlueprintService`):
- `FetchHTML(url) → { html, cleaned_html, status_code }` — Fetch and clean a page via Firecrawl
- `GenerateBlueprint(cleaned_html, schema_type) → { extraction_rules, test_results }` — Generate a blueprint using OpenAI
- `TestBlueprint(url, extraction_rules, schema_type) → { entities, errors }` — Test a blueprint against a live URL

The worker is the **only** service that talks to Firecrawl and OpenAI. The web app never makes these calls directly.

### Future RPCs

- `RepairBlueprint(blueprint_id) → { updated_rules, diff }` — Self-healing when extraction breaks

---

## Web Application

### Layout

Based on the shadcn sidebar-7 example. Sidebar navigation with:
- **Dashboard**: Overview of recent events, watch health, key metrics
- **Sources**: CRUD for sources
- **Blueprints**: Blueprint management, generation wizard
- **Watches**: Watch management, status overview, manual trigger
- **Events**: Event log with filtering
- **Subscriptions**: Subscription management
- **Settings**: Org settings, API keys (post-MVP)

### Key Flows

**Blueprint Generation Wizard:**
1. Select or create a Source
2. Enter a URL from that source
3. Select an entity schema (e.g., ecommerce_product)
4. Choose extraction mode: single item or list
5. Click "Generate" — calls worker via gRPC
6. Preview extracted data
7. Save or adjust and regenerate

**Watch Creation:**
1. Select a Source and Blueprint
2. Enter the URL to monitor
3. Set the schedule (cron picker or presets: every 15min, hourly, daily)
4. Activate

---

## Worker Architecture

### Watch Scheduler

- Polls the `watches` table periodically (every 30 seconds) for watches where `next_run_at <= now()` and `status = 'active'`
- Executes watches concurrently with a configurable worker pool size (default: 5)
- Updates `last_run_at` and `next_run_at` after each run
- Implements circuit breaking: after 3 consecutive failures, sets watch status to `error`

### Delivery Processor

- Polls the `deliveries` table periodically (every 10 seconds) for deliveries where `status = 'pending'` and `next_retry_at <= now()`
- Processes deliveries concurrently with a configurable pool size (default: 3)
- Webhook delivery: POST to the configured URL with event payload, expect 2xx response
- Email delivery: via a transactional email provider (post-MVP, Resend or similar)
- Slack delivery: via incoming webhook URL

### Rate Limiting

- Per-source rate limiting: configurable delay between requests to the same source (default: 2 seconds)
- Global concurrency limit: max simultaneous Firecrawl requests (default: 5)
- Per-org limits (post-MVP): prevent a single org from consuming all resources

---

## MVP Scope

### In Scope
- Source CRUD
- Blueprint generation and testing via worker
- Blueprint CRUD
- Watch CRUD with cron scheduling
- Entity extraction and storage
- Diff engine (field-level)
- Event emission (entity_appeared, entity_disappeared, entity_changed)
- Subscription CRUD (webhook channel only)
- Delivery with retry logic
- WorkOS auth with org-based multitenancy
- One entity schema: `ecommerce_product`
- Dashboard with event log

### Out of Scope (Post-MVP)
- Pagination support in blueprints
- Email and Slack delivery channels
- Subscription batching/digest mode
- Self-repairing blueprints
- Per-org rate limits
- User roles and permissions
- API keys for external access
- Job vacancy entity schema
- Billing/usage tracking
